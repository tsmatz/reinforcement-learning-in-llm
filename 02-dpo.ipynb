{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "857cafc6-da38-4aa7-8afc-63aa626fa7aa",
   "metadata": {},
   "source": [
    "# DPO (Direct Preference Optimization)\n",
    "\n",
    "As you saw in [RLHF tutorial](./01-rlhf-ppo.ipynb), total 3 models - reward model, policy model (LLM), and value model - are used in RLHF.<br>\n",
    "Reward model and value model are similar. (Both models predict reward's values and the difference is that reward model predicts only on the last token.) Multiple training - preference model traininig and llm reward training - will also be time-consuming and lose the training efficiency.<br>\n",
    "Direct Preference Optimization (shortly, DPO) shotcuts this duplication, and directly optimize a policy (i.e., LLM) to align the given preference without explicit reward scores.\n",
    "\n",
    "In DPO, we try to represent preference loss by using a policy and optimize preference by policy updates, without explicit reward functions.<br>\n",
    "By the absence of absolute rewards, DPO provides simple and efficient (not wasting time and resources) optimization.<br>\n",
    "It's worth noting that **DPO is not a reinforcement learning method** (the term \"reinforcement learning\" is used for optimization by explicit rewards), but it's derived from previous RLHF process.\n",
    "\n",
    "Before jumping into implementation, let's briefly see theoretical aspects behind DPO, along with [[Rafailov et al., 2023](https://arxiv.org/pdf/2305.18290)].\n",
    "\n",
    "---\n",
    "\n",
    "Firstly, we start with reinforcement learning process by PPO in RLHF process.<br>\n",
    "As you saw in [RLHF tutorial](./01-rlhf-ppo.ipynb), the objective in this phase is to maximize the following expectation.\n",
    "\n",
    "$\\displaystyle \\mathbb{E}_{x,\\;y \\sim \\pi_{\\theta}(y|x)} \\left[ r(x, y) - \\beta \\verb|KL| ( \\pi_{\\theta} \\| \\pi_{\\verb|ref|} ) \\right] $\n",
    "\n",
    "i.e.,\n",
    "\n",
    "$\\displaystyle \\mathbb{E}_{x,\\;y \\sim \\pi_{\\theta}(y|x)} \\left[ r(x, y) - \\beta \\log \\frac{\\pi_{\\theta}(y|x)}{\\pi_{\\verb|ref|}(y|x)} \\right] $\n",
    "\n",
    "where\n",
    "\n",
    "- $x$ is a state (input context in language model), which is on dataset distribution.\n",
    "- $r(x, y)$ is a reward function.\n",
    "- $\\pi_{\\theta}(\\cdot)$ is a new policy to be updated.\n",
    "- $\\pi_{\\verb|ref|}(\\cdot)$ is a starting policy trained by SFT. (This corresponds to $\\pi_{\\verb|old|}(\\cdot)$ in previous [RLHF tutorial](./01-rlhf-ppo.ipynb).)\n",
    "- $\\verb|KL|(P \\| Q)$ is KL divergence between the distribution $P$ and $Q$.\n",
    "- $\\beta$ is a coefficient (hyperparameter in the training) which represents the ratio of KL divergence loss.\n",
    "\n",
    "> Note : Unlike previous [RLHF tutorial](./01-rlhf-ppo.ipynb), reverse KL-divergence $\\verb|KL| ( \\pi_{\\theta} \\| \\pi_{\\verb|ref|} )$ is used, because $y$ is on a new policy $\\pi_{\\theta}$ in this expectation. (In previous [RLHF tutorial](./01-rlhf-ppo.ipynb), on contrary, sampling is on an old policy.)\n",
    "\n",
    "This optimization is equivalent to **minimization** of the following formula.\n",
    "\n",
    "$\\displaystyle \\log \\frac{\\pi_{\\theta}(y|x)}{\\pi_{\\verb|ref|}(y|x)} - \\frac{1}{\\beta} r(x,y) $\n",
    "\n",
    "$\\displaystyle = \\log \\frac{\\pi_{\\theta}(y|x)}{\\frac{1}{Z(x)} \\pi_{\\verb|ref|}(y|x) \\exp\\left( \\frac{1}{\\beta} r(x,y) \\right)} - \\log Z(x)$\n",
    "\n",
    "where $Z(x)$ is an arbitrary formula, depending only on state $x$.\n",
    "\n",
    "We now set $Z(x)$ as follows.<br>\n",
    "Here $y$ is all possible actions, and $Z(x)$ doesn't depend on $\\pi_{\\theta}$ or $y \\sim \\pi_{\\theta}(y|x)$.\n",
    "\n",
    "$\\displaystyle Z(x) = \\sum_y \\pi_{\\verb|ref|}(y|x) \\exp\\left( \\frac{1}{\\beta} r(x,y) \\right)$\n",
    "\n",
    "Now we define $\\pi^{\\ast}(y|x)$ as follows.<br>\n",
    "This is a valid distribution, because $0 \\leq \\pi^{\\ast}(y|x) \\leq 1$ and $\\sum_y \\pi^{\\ast}(y|x) = 1$.\n",
    "\n",
    "$\\displaystyle \\pi^{\\ast}(y|x) = \\frac{1}{Z(x)} \\pi_{\\verb|ref|}(y|x) \\exp\\left( \\frac{1}{\\beta} r(x,y) \\right) $\n",
    "\n",
    "Our objective is then to minimize :\n",
    "\n",
    "$\\displaystyle \\mathbb{E}_{y \\sim \\pi_{\\theta}(y|x)} \\left[ \\log \\frac{\\pi_{\\theta}(y|x)}{\\pi^{\\ast}(y|x)} \\right] - \\log Z(x)$\n",
    "\n",
    "$\\displaystyle =\\verb|KL|(\\pi_{\\theta} \\| \\pi^{\\ast}) - \\log Z(x)$\n",
    "\n",
    "KL divergence $\\verb|KL|(P \\| Q)$ is equal to zero when $P=Q$, and $\\verb|KL|(P \\| Q) > 0$ otherwise. Therefore, $\\pi_{\\theta}$ should follow :\n",
    "\n",
    "$\\displaystyle \\pi_{\\theta}(y|x)=\\pi^{\\ast}(y|x)=\\frac{1}{Z(x)} \\pi_{\\verb|ref|}(y|x) \\exp\\left( \\frac{1}{\\beta} r(x,y) \\right)$\n",
    "\n",
    "Now we have an optimal policy representation by using a given reward function $r(x,y)$.<br>\n",
    "We can then represent $r(x,y)$ by using an optimal policy $\\pi_{\\theta}(y|x)$ as follows, vice versa.\n",
    "\n",
    "$\\displaystyle r(x,y) = \\beta \\log \\frac{\\pi_{\\theta}(y|x)}{\\pi_{\\verb|ref|}(y|x)} + \\beta \\log Z(x) \\;\\;\\;\\;\\;\\; (1)$\n",
    "\n",
    "Now we can get a reward representation by using an optimal policy $\\pi_{\\theta}(y|x)$, and we then finally try to optimize a reward with this representation by using [Bradleyâ€“Terry model](https://en.wikipedia.org/wiki/Bradley%E2%80%93Terry_model), which is discussed in previous [RLHF tutorial](./01-rlhf-ppo.ipynb).\n",
    "\n",
    "Please remind that Bradleyâ€“Terry model represents the preference as follows, in which $y_1$ is more preferable output than $y_2$.\n",
    "\n",
    "$\\displaystyle p(y_1 \\succ y_2 | x) = \\frac{\\exp(r(x, y_1))}{\\exp(r(x, y_1)) + \\exp(r(x, y_2))} = \\frac{1}{1 + \\exp(r(x, y_2) - r(x, y_1))}$\n",
    "\n",
    "As you can see above, Bradley-Terry model depends only on the difference of rewards, $r(x, y_2) - r(x, y_1)$. Therefore, now $Z(x)$ is canceled and we get the following equation by substituting (1).\n",
    "\n",
    "$\\displaystyle p(y_1 \\succ y_2 | x)$\n",
    "\n",
    "$\\displaystyle = \\frac{1}{1 + \\exp\\left( \\beta \\log \\frac{\\pi_{\\theta}(y_2|x)}{\\pi_{\\verb|ref|}(y_2|x)} - \\beta \\log \\frac{\\pi_{\\theta}(y_1|x)}{\\pi_{\\verb|ref|}(y_1|x)} \\right)}$\n",
    "\n",
    "$\\displaystyle = \\sigma\\left( \\beta \\log \\frac{\\pi_{\\theta}(y_1|x)}{\\pi_{\\verb|ref|}(y_1|x)} - \\beta \\log \\frac{\\pi_{\\theta}(y_2|x)}{\\pi_{\\verb|ref|}(y_2|x)} \\right) \\;\\;\\;\\;\\;\\; (2)$\n",
    "\n",
    "where $\\sigma(\\cdot)$ is [a sigmoid function](https://tsmatz.wordpress.com/2017/08/30/regression-in-machine-learning-math-for-beginners/).\n",
    "\n",
    "> Note : DPO is usually discussed in binary preference optimization, but the same transformation (cancellation of $Z(x)$) can also be applied to multiple rated answers. See Appendix A.3 in the [original paper](https://arxiv.org/pdf/2305.18290).\n",
    "\n",
    "As a result, our objective is to minimize the following loss in the training. (Same as [RLHF tutorial](./01-rlhf-ppo.ipynb), I have applied a logarithm for above equation (2).)\n",
    "\n",
    "$\\displaystyle L_{DPO} = -\\log \\sigma\\left( \\beta \\log \\frac{\\pi_{\\theta}(y_1|x)}{\\pi_{\\verb|ref|}(y_1|x)} - \\beta \\log \\frac{\\pi_{\\theta}(y_2|x)}{\\pi_{\\verb|ref|}(y_2|x)} \\right) \\;\\;\\;\\;\\;\\; (3)$\n",
    "\n",
    "---\n",
    "\n",
    "Now let's see the code (implementation) step-by-step.\n",
    "\n",
    "Throughout this notebook, I have used pretrained model in Hugging Face, but **I manually configure and run training with regular PyTorch training loop** (i.e., won't use any built-in class in Hugging Face) not to make the implementation black-boxed.\n",
    "\n",
    "> Note : Compared to RLHF, DPO sometimes suffers from the issue of distribution shift (i.e., struggle to generalize) in difficult problems.<br>\n",
    "> The refined [MPO (Mixed Preference Optimization)](https://arxiv.org/pdf/2403.19443) method will address this issue by hybrid training with both RLHF and DPO.\n",
    "\n",
    "*(back to [index](https://github.com/tsmatz/reinforcement-learning-in-llm/))*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5344efcc-98be-4f2e-8f6c-c355466a77da",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552467da-f1fc-452b-9684-4aa8c4665d09",
   "metadata": {},
   "source": [
    "Before we start, we need to install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636cd1d7-2218-42ec-acd1-84cccb566e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers datasets matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50fc9c0-a773-47e0-9b77-9149cb2d6926",
   "metadata": {},
   "source": [
    "## Prepare Dataset\n",
    "\n",
    "Before training a model, we should prepare (preprocess) the training dataset.\n",
    "\n",
    "In this example, we use dataset, [Human-Like-DPO-Dataset](https://huggingface.co/datasets/HumanLLMs/Human-Like-DPO-Dataset), for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77faeaa-a81c-4bd8-b1ca-94eaee62fa3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected'],\n",
       "    num_rows: 10884\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "all_data = load_dataset(\"HumanLLMs/Human-Like-DPO-Dataset\")\n",
    "train_data = all_data[\"train\"]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8a1afe-b83e-40aa-94bf-47902b9eb74f",
   "metadata": {},
   "source": [
    "This dataset has 2 labels, \"```chosen```\" and \"```rejected```\", which is respectively a preferred response (i.e., more natural and informal response) and a non-preferred response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b8cb328-765a-48f7-b07f-cf2311ba6414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** prompt **********\n",
      "Oh, I just saw the best meme - have you seen it?\n",
      "********** chosen **********\n",
      "ðŸ˜‚ Ah, no I haven't! I'm dying to know, what's the meme about? Is it a funny cat or a ridiculous situation? Spill the beans! ðŸ¤£\n",
      "********** rejected **********\n",
      "I'm an artificial intelligence language model, I don't have personal experiences or opinions. However, I can provide you with information on highly-rated and critically acclaimed films, as well as recommendations based on specific genres or themes. Would you like me to suggest some notable movies or discuss a particular genre of interest?\n",
      "********** end **********\n"
     ]
    }
   ],
   "source": [
    "row_num = 0\n",
    "print(\"********** prompt **********\")\n",
    "print(train_data[\"prompt\"][row_num])\n",
    "print(\"********** chosen **********\")\n",
    "print(train_data[\"chosen\"][row_num])\n",
    "print(\"********** rejected **********\")\n",
    "print(train_data[\"rejected\"][row_num])\n",
    "print(\"********** end **********\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a17e535-f24d-48b9-99fc-c72ca8d8c8da",
   "metadata": {},
   "source": [
    "Now we convert this data into the following text format, fitting for SmolLM2-Instruct inputs.<br>\n",
    "In this format, the user role in chat message is \"```<|im_start|>user\\n...<|im_end|>```\" and the assistant role in chat message is \"```<|im_start|>assistant\\n...<|im_end|>```\".\n",
    "\n",
    "```\n",
    "<|im_start|>user\n",
    "Oh, I just saw the best meme - have you seen it?<|im_end|>\n",
    "<|im_start|>assistant\n",
    "ðŸ˜‚ Ah, no I haven't! I'm dying to know, what's the meme about? Is it a funny cat or a ridiculous situation? Spill the beans! ðŸ¤£<|im_end|>\n",
    "```\n",
    "\n",
    "> Note : If you want to include system role, use \"```<|im_start|>system\\n...<|im_end|>```\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aa7c02a-060f-47ca-81b0-2469ad096987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_to_chatml(example):\n",
    "    return {\n",
    "        \"chosen\": f\"<|im_start|>user\\n{example[\"prompt\"]}<|im_end|>\\n<|im_start|>assistant\\n{example[\"chosen\"]}<|im_end|>\",\n",
    "        \"rejected\": f\"<|im_start|>user\\n{example[\"prompt\"]}<|im_end|>\\n<|im_start|>assistant\\n{example[\"rejected\"]}<|im_end|>\",\n",
    "    }\n",
    "\n",
    "original_columns = train_data.column_names\n",
    "train_data = train_data.map(format_to_chatml, remove_columns=original_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4185453d-acfe-42b8-9789-5b0801070b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** chosen **********\n",
      "<|im_start|>user\n",
      "Oh, I just saw the best meme - have you seen it?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "ðŸ˜‚ Ah, no I haven't! I'm dying to know, what's the meme about? Is it a funny cat or a ridiculous situation? Spill the beans! ðŸ¤£<|im_end|>\n",
      "********** rejected **********\n",
      "<|im_start|>user\n",
      "Oh, I just saw the best meme - have you seen it?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "I'm an artificial intelligence language model, I don't have personal experiences or opinions. However, I can provide you with information on highly-rated and critically acclaimed films, as well as recommendations based on specific genres or themes. Would you like me to suggest some notable movies or discuss a particular genre of interest?<|im_end|>\n",
      "********** end **********\n"
     ]
    }
   ],
   "source": [
    "row_num = 0\n",
    "print(\"********** chosen **********\")\n",
    "print(train_data[\"chosen\"][row_num])\n",
    "print(\"********** rejected **********\")\n",
    "print(train_data[\"rejected\"][row_num])\n",
    "print(\"********** end **********\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae72f8d-4261-40b0-ad25-0877822a992e",
   "metadata": {},
   "source": [
    "## Run Supervised Fine-tuning (SFT)\n",
    "\n",
    "Same as in [RLHF example](./01-rlhf-ppo.ipynb), we firstly apply SFT (Supervised Fine-tuning) using good samples (\"chosen\" tokens), because the actual model's outputs are not used in this training.<br>\n",
    "Later in DPO training, this trained model will be used as a reference model.\n",
    "\n",
    "> Note : If you have already applied [RLHF example](./01-rlhf-ppo.ipynb), you can skip this section and use the trained ```llm_sft```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b420848-3c05-4dc8-87b7-aca5c8a7432c",
   "metadata": {},
   "source": [
    "First we download [SmolLM2-Instruct (135M)](https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct) model and its tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de3de214-80a6-4a32-8a81-d81e42574d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "torch.set_default_dtype(torch.bfloat16) # because SmolLM2-Instruct is trained on bf16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e40e391-bd88-4e18-b4ff-f6a39c259cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "base_model_name = \"HuggingFaceTB/SmolLM2-135M-Instruct\"\n",
    "\n",
    "# download model\n",
    "config = AutoConfig.from_pretrained(base_model_name)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    config=config,\n",
    ").to(device)\n",
    "\n",
    "# download tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d57a539-d269-45b4-abba-36ba6fe20224",
   "metadata": {},
   "source": [
    "We build dataloader in order to feed data to the trainer.<br>\n",
    "In SFT, we use only good samples (\"```chosen```\" tokens) and train on tokens of entire sequence, including both inputs and completions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53fcd67d-2c9f-4fa1-a19a-82435be2dc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 4\n",
    "gradient_accumulation_steps = 8\n",
    "\n",
    "def collate_batch(batch):\n",
    "    itr_batch_size = len(batch)\n",
    "\n",
    "    # tokenize (convert to token ids and attention mask) and convert to tensor\n",
    "    token_list = [item[\"chosen\"] for item in batch]\n",
    "    token_tensor = tokenizer(\n",
    "        token_list,\n",
    "        padding=True,\n",
    "        padding_side=\"right\",\n",
    "        return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # generate labels for SFT\n",
    "    labels = token_tensor[\"input_ids\"][:,1:].clone()\n",
    "    # generate inputs for SFT\n",
    "    last_nonpad_indices = token_tensor[\"attention_mask\"].sum(dim=1) - 1  # note: valid only in right padding\n",
    "    token_tensor[\"input_ids\"][torch.arange(itr_batch_size).to(device),last_nonpad_indices] = tokenizer.pad_token_id  # note: this is not needed, because the final token is always pad token\n",
    "    token_tensor[\"attention_mask\"][torch.arange(itr_batch_size).to(device),last_nonpad_indices] = 0\n",
    "    inputs = token_tensor[\"input_ids\"][:,:-1]\n",
    "    masks = token_tensor[\"attention_mask\"][:,:-1]\n",
    "\n",
    "    return inputs, labels, masks\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f3e31e-b0da-4d7e-8706-1f050dc7b9be",
   "metadata": {},
   "source": [
    "Now we train our base model.\n",
    "\n",
    "> Note : In order to prevent from GPU out of memory errors, I have used accumulation training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5036c3bc-cfb5-4e90-b9a0-e3457414de3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (iter2721) 341/341 - loss 2.2344\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os, math\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import functools\n",
    "\n",
    "num_epochs = 1\n",
    "num_steps = math.ceil(len(dataloader) / gradient_accumulation_steps)\n",
    "\n",
    "# prepare optimizer and scheduler\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=base_model.parameters(),\n",
    "    lr=9.0e-6,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-08,\n",
    ")\n",
    "\n",
    "def _get_cosine_schedule(\n",
    "    current_step: int,\n",
    "    num_training_steps: int,\n",
    "    num_warmup_steps: int=0,\n",
    "    linear_warmup: bool=False,\n",
    "    min_value: float=0.0,\n",
    "):\n",
    "    if current_step < num_warmup_steps:\n",
    "        if linear_warmup:\n",
    "            return min(1.0, (current_step + 1) / (num_warmup_steps + 1))  # see https://arxiv.org/abs/2410.11020\n",
    "        else:\n",
    "            return 1.0\n",
    "    progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "    scale = 0.5 * (1.0 + math.cos(math.pi * progress))\n",
    "    return (1.0 - min_value) * scale + min_value\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=functools.partial(\n",
    "    _get_cosine_schedule,\n",
    "    num_training_steps=num_epochs*num_steps,\n",
    "    min_value=0.3,\n",
    "))\n",
    "\n",
    "# remove log file if exists\n",
    "log_file = \"loss_sft.log\"\n",
    "if os.path.exists(log_file):\n",
    "    os.remove(log_file)\n",
    "\n",
    "# iterate epoch\n",
    "for epoch in range(num_epochs):\n",
    "    base_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    record_loss = []\n",
    "\n",
    "    # iterate batch\n",
    "    for i, (inputs, labels, masks) in enumerate(dataloader):\n",
    "        with torch.set_grad_enabled(True):\n",
    "            # get logits and values to be optimized\n",
    "            outputs = base_model(\n",
    "                input_ids=inputs,\n",
    "                attention_mask=masks,\n",
    "            )\n",
    "\n",
    "            # compute loss\n",
    "            loss = F.cross_entropy(outputs.logits.transpose(1,2), labels)\n",
    "            record_loss.append(loss.item())\n",
    "\n",
    "            # optimize\n",
    "            loss.backward()\n",
    "            if ((i + 1) % gradient_accumulation_steps == 0) or \\\n",
    "               (i + 1 == len(dataloader)):\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "    \n",
    "            # print log\n",
    "            print(f\"Epoch {epoch+1} (iter{i+1}) {math.ceil((i + 1) / gradient_accumulation_steps)}/{num_steps} - loss {loss :5.4f}\", end=\"\\r\")\n",
    "\n",
    "    # save log in epoch\n",
    "    with open(log_file, \"a\") as f:\n",
    "        for l in record_loss:\n",
    "            f.write(\"%s\\n\" %l)\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "# save checkpoint\n",
    "### torch.save(base_model.state_dict(), \"llm_sft.pt\")\n",
    "base_model.save_pretrained(\"./llm_sft\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ab8216-e860-4772-989f-ca7693eddf82",
   "metadata": {},
   "source": [
    "Show loss transition in the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bda0ffb8-6f5d-45a5-9812-379f23f01155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "log_file = \"loss_sft.log\"\n",
    "\n",
    "with open(log_file, \"r\") as f:\n",
    "    data = [float(line) for line in f]\n",
    "\n",
    "# show plot of every 50 interval average\n",
    "interval = 50\n",
    "avg = []\n",
    "for i in range(interval, len(data)):\n",
    "    tmp_list = data[i-interval+1:i+1]\n",
    "    avg.append(np.average(tmp_list))\n",
    "plt.plot(np.arange(interval, len(data)), avg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e842e9-a94a-4aea-a177-9e4d201c621a",
   "metadata": {},
   "source": [
    "## Test trained model (SFT-ed model)\n",
    "\n",
    "In order to test our fine-tuned model, we generate outputs for the following example questions. (This result is also same as [RLHF example](./01-rlhf-ppo.ipynb).)\n",
    "\n",
    "> Note : In this function (```generate_token_by_policy```), here we use **attention cache** for sequential token generation to speed up.<br>\n",
    "> And, in order to avoid GPU memory errors in optimization, we also limit the number of tokens in sequence (by ```max_seq_len``` parameter).\n",
    "\n",
    "> Note : For practical token generation, use more huristic search algorithms - such as, beam search. (Here I have simply used greedy search for test purpose.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c84cfbd-2c67-447a-8ebc-4daa354d5f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DynamicCache\n",
    "\n",
    "def generate_token_by_policy(\n",
    "    chat_data,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    max_seq_len,\n",
    "):\n",
    "    \"\"\"\n",
    "    Collect samples with a model (LLM) as a batch.\n",
    "    To speed up generation, here we use attention cache.\n",
    "    All tensors are collected with no gradient (as detached tensors).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    chat_data : dic(\n",
    "            input_ids: torch.tensor((batch_size, seq_len), dtype=int),\n",
    "            attention_mask: torch.tensor((batch_size, seq_len), dtype=int)\n",
    "        )\n",
    "        Chat template data to be fed as a batch.\n",
    "        The format should be left-side padding, and shouldn't include the\n",
    "        final assistant's message, because it'll be generated in this function.\n",
    "        (The length of input's sequence (seq_len) might differ in each call.)\n",
    "    model : torch.nn.Module\n",
    "        A model which is used to pick up an action (i.e., a token).\n",
    "        In this function, the output is generated with no gradient.\n",
    "    tokenizer : transformers.PreTrainedTokenizer\n",
    "        Hugging Face tokenizer class to be used in this model.\n",
    "    max_seq_len : int\n",
    "        Maximum sequence length. (See above description.)\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    completion_ids : torch.tensor((batch_size, seq_len), dtype=int)\n",
    "        The array of token id for generated chat completion (including context tokens).\n",
    "        The length of result's sequence (i.e., seq_len) differs depending\n",
    "        on the results.\n",
    "    completion_mask : torch.tensor((batch_size, seq_len), dtype=int)\n",
    "        Corresponding attention mask.\n",
    "    \"\"\"\n",
    "\n",
    "    # get batch size\n",
    "    batch_size = chat_data[\"input_ids\"].shape[0]\n",
    "\n",
    "    # initialize inputs\n",
    "    cur_iids = chat_data[\"input_ids\"]\n",
    "    cur_mask = chat_data[\"attention_mask\"]\n",
    "\n",
    "    # initialize a flag for processing/finish in a batch\n",
    "    # (True: processing, False: finished)\n",
    "    proceed_flag = torch.ones(batch_size, dtype=bool).to(device)\n",
    "\n",
    "    # initialize cache parameters\n",
    "    cache_position = None\n",
    "    past_key_values = DynamicCache()\n",
    "\n",
    "    # loop until all is done\n",
    "    done_tokens_num = 0\n",
    "    while(torch.any(proceed_flag)):\n",
    "        # get current sequence length\n",
    "        cur_seq_len = cur_iids.shape[1]\n",
    "\n",
    "        # get the final non-pad token indices in sequence\n",
    "        # --> shape:[batch_size]\n",
    "        token_indices = torch.arange(cur_seq_len, dtype=int).to(device)\n",
    "        last_nonpad_indices = (token_indices * cur_mask).argmax(-1)\n",
    "\n",
    "        # run inference (with no gradient !)\n",
    "        if cache_position is None:\n",
    "            # get initial cache position\n",
    "            cache_position = torch.arange(cur_seq_len, dtype=int, device=device)\n",
    "            # compute logits for all input_ids\n",
    "            logits = model(\n",
    "                input_ids=cur_iids,\n",
    "                attention_mask=cur_mask,\n",
    "                cache_position=cache_position,\n",
    "                past_key_values=past_key_values,\n",
    "                use_cache=True,\n",
    "            ).logits.detach()\n",
    "            # need only final output in sequence --> shape:[batch_size, vocab_size]\n",
    "            logits = logits[torch.arange(batch_size).to(device), last_nonpad_indices, :]\n",
    "        else:\n",
    "            # compute logits only for the last input_ids\n",
    "            # (others are all cached.)\n",
    "            logits = model(\n",
    "                input_ids=cur_iids[:,-1:],\n",
    "                attention_mask=cur_mask,\n",
    "                cache_position=cache_position,\n",
    "                past_key_values=past_key_values,\n",
    "                use_cache=True,\n",
    "            ).logits.detach()\n",
    "            # reshape to [batch_size, vocab_size]\n",
    "            logits = logits.squeeze(1)\n",
    "\n",
    "        # select a token (i.e., take an action)\n",
    "        # --> shape:[batch_size]\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        selected_ids = torch.multinomial(probs, num_samples=1).squeeze(-1)\n",
    "\n",
    "        # get next token indices in sequence\n",
    "        # --> shape:[batch_size]\n",
    "        next_token_indices = last_nonpad_indices + proceed_flag.int()\n",
    "\n",
    "        # expand inputs when it exceeds\n",
    "        # --> shape:[batch_size, cur_seq_len+1]\n",
    "        if next_token_indices.max() > cur_seq_len - 1:\n",
    "            cur_iids = F.pad(input=cur_iids, pad=(0, 1, 0, 0), mode=\"constant\", value=tokenizer.pad_token_id)\n",
    "            cur_mask = F.pad(input=cur_mask, pad=(0, 1, 0, 0), mode=\"constant\", value=0)\n",
    "\n",
    "        # store new token ids\n",
    "        cur_iids[proceed_flag, next_token_indices[proceed_flag]] = selected_ids[proceed_flag]\n",
    "\n",
    "        # store new attention mask\n",
    "        cur_mask[proceed_flag, next_token_indices[proceed_flag]] = 1\n",
    "\n",
    "        # update cache_position\n",
    "        cache_position = cache_position[-1:] + 1\n",
    "\n",
    "        # update proceed_flag\n",
    "        not_lim = (cur_mask.sum(dim=1) < max_seq_len)\n",
    "        is_eos = torch.logical_and((selected_ids == tokenizer.eos_token_id),proceed_flag.bool())\n",
    "        not_eos = torch.logical_not(is_eos)\n",
    "        proceed_flag = torch.logical_and(proceed_flag, torch.logical_and(not_lim, not_eos))\n",
    "\n",
    "    return cur_iids, cur_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fd5e6d6-293a-4d57-ab25-a382aceed7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Question *****\n",
      "What do you most want to do right now?\n",
      "***** Answer *****\n",
      "Where do I even start? I want to move on, to create something beautiful from scratch, something that will be a part of me for years to come. I envision a city on wheels, where every ray of light, every smile, and every crumpled up canvas flips the design over, and creates a message all its own.\n",
      "\n",
      "I want to create a mural, something that I can still take home years from now. I want the same colors, the same pattern, and no lines. My art will be unique, with a story behind it, and a story that starts from scratch in my mind.\n",
      "\n",
      "I also want to create a video game that responds to my emotions. I want characters that can see the light of day, identify with the gravity of the situation, and respond to my emotions in a way that feels almost organic.\n",
      "\n",
      "And, of course, there's the dreamy, beautiful landscapes of the city I'm creating. I want the buildings, the streets, the colors, and shapes to merge into one cohesive piece of art. I want to see art in my sleep, or through the eyes of a vintage clown in a time machine.\n",
      "\n",
      "I want to create something that is present in every walk of life, something that transcends borders, cultures, and ages. I want my work to reflect the diversity, the messiness, and the beauty of humanity.\n",
      "\n",
      "It's a daunting task, but I'm excited to take the leap and start building something truly magical.\n",
      "\n",
      "***** Question *****\n",
      "What is the best gift to give a friend who loves the outdoors?\n",
      "***** Answer *****\n",
      "To create a thoughtful and thoughtful gift for your friend who loves the outdoors, consider items that not only give them a unique experience but also reflect their personality and interests. For a casual getaway or weekend getaway, you can choose a decent-sized vehicle, nice looking roadside or recreational gear, and some outdoor games and equipment.\n",
      "\n",
      "However, if you have more limited collections or preferences, you could also think about gifts that are practical and make their trips enjoyable. For example, if they're interested in hiking gear or mapping a scenic route, you could pack a backpack with essentials and take some customized hiking boots.\n",
      "\n",
      "If they're into sports or adventure-driven activities, you could put on an outdoor clothing planner and book some recreational activities, such as fishing trips, fishing trips with campers, or camping excursions. If they're interested in learning about the local wildlife or experiencing a wildlife-friendly outdoor event, you could arrange for guided tours or excursions with professionals in their interests.\n",
      "\n",
      "Overall, a thoughtful gift that reflects their personality and preferences should not only accommodate their needs but also bring a sense of fun and enjoyment to your time together and create lasting memories.\n",
      "\n",
      "***** Question *****\n",
      "How do you relax after something bad happens?\n",
      "***** Answer *****\n",
      "Relaxation after a stressful experience is essential to prioritize your own well-being and maintain a positive mindset. One effective approach is to approach the situation with a sense of detachment and mindfulness. Allow yourself to breathe and slow down by letting go of any thoughts or emotions that might be contributing to your anxiety.\n",
      "\n",
      "Try to focus on the present moment, no matter how short it may seem, rather than dwelling on past regrets or planning solutions. Allow yourself to feel the stress and discomfort of the experience, releasing any physical tension or physical sensations that might raise concerns about your resilience.\n",
      "\n",
      "Consider activities that bring you joy, relaxation, or tranquility, such as taking a day trip, reading, or practicing deep breathing exercises. This can help distract your mind from the hindrance and cultivate a sense of flexibility and well-being.\n",
      "\n",
      "It's also essential to prioritize self-care, engaging in activities that promote physical and mental relaxation, and remembering why you stayed and acted when needed. This can be a great way to recharge and regain a sense of control over your situation, even if immediate relief doesn't arrive.\n",
      "\n",
      "Ultimately, relaxation is an ongoing process that requires patience, self-compassion, and self-awareness. By acknowledging that it's okay to feel uncomfortable or anxious, you can begin to make adjustments to ensure a more balanced and positive outlook from the start.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 768\n",
    "\n",
    "#\n",
    "# build a batch of questions\n",
    "# (To use cache, we apply left-side padding.)\n",
    "#\n",
    "\n",
    "messages = [\n",
    "    \"What do you most want to do right now?\",\n",
    "    \"What is the best gift to give a friend who loves the outdoors?\",\n",
    "    \"How do you relax after something bad happens?\",\n",
    "]\n",
    "inputs = [f\"<|im_start|>user\\n{m}<|im_end|>\\n<|im_start|>assistant\\n\" for m in messages]\n",
    "input_batch = tokenizer(\n",
    "    inputs,\n",
    "    padding=True,\n",
    "    padding_side=\"left\",\n",
    "    return_tensors=\"pt\").to(device)\n",
    "input_seq_len = input_batch[\"input_ids\"].shape[1]\n",
    "\n",
    "#\n",
    "# generate model's outputs\n",
    "#\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\"./llm_sft\").to(device)\n",
    "base_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    iids, mask = generate_token_by_policy(\n",
    "        input_batch,\n",
    "        base_model,\n",
    "        tokenizer,\n",
    "        max_seq_len,\n",
    "    )\n",
    "iids = iids[:,input_seq_len:]\n",
    "outputs = tokenizer.batch_decode(iids, skip_special_tokens=True)\n",
    "\n",
    "#\n",
    "# print results\n",
    "#\n",
    "\n",
    "for i in range(len(messages)):\n",
    "    print(\"***** Question *****\")\n",
    "    print(messages[i])\n",
    "    print(\"***** Answer *****\")\n",
    "    print(outputs[i])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803f75d7-9be0-4f91-9284-69ad7e15f137",
   "metadata": {},
   "source": [
    "## Run DPO training\n",
    "\n",
    "Now let's try to optimize model with DPO, following the algorithm explained above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f10b0-5d2f-4ee6-beae-757a7a8caaaa",
   "metadata": {},
   "source": [
    "### 1. Load a policy model\n",
    "\n",
    "For a policy model (actor) $\\pi_{\\theta}$, I load fine-tuned LLM (SFT model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5de5f868-20c8-4ed6-bdd1-190dc8a1a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_model = AutoModelForCausalLM.from_pretrained(\"./llm_sft\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2442c428-9f5c-4d01-bf60-3ed7517a059c",
   "metadata": {},
   "source": [
    "### 2. Load a reference model\n",
    "\n",
    "For a reference model $\\pi_{\\verb|ref|}$, I use the same model, but it'll only be used for ineference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0411b20e-63a0-4d08-8e8b-656bedc78401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(49152, 576, padding_idx=2)\n",
       "    (layers): ModuleList(\n",
       "      (0-29): 30 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=576, out_features=576, bias=False)\n",
       "          (k_proj): Linear(in_features=576, out_features=192, bias=False)\n",
       "          (v_proj): Linear(in_features=576, out_features=192, bias=False)\n",
       "          (o_proj): Linear(in_features=576, out_features=576, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=576, out_features=1536, bias=False)\n",
       "          (up_proj): Linear(in_features=576, out_features=1536, bias=False)\n",
       "          (down_proj): Linear(in_features=1536, out_features=576, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((576,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=576, out_features=49152, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_model = AutoModelForCausalLM.from_pretrained(\"./llm_sft\").to(device)\n",
    "ref_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b9d1bf-90be-496d-abd6-1de54060d13f",
   "metadata": {},
   "source": [
    "### 3. Create dataset\n",
    "\n",
    "In order to reduce memory consumption (prevent from GPU out of memory errors), we now filter data not to exceed a certain length of tokens.\n",
    "\n",
    "> Note : In my experiment, I have used NVIDIA Tesla T4. Depending on your environment, you can increase the maximum sequence length.<br>\n",
    "> The operable maximum sequence length in ```SmolLM2-Instruct 135M``` is 8192. (See ```tokenizer.model_max_length```.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "044525bb-ac50-4956-8e0e-9541f30b4b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['chosen', 'rejected'],\n",
       "    num_rows: 10820\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. add \"chosen_len\" and \"rejected_len\" column\n",
    "#   (which indicates the sequence length in \"chosen\" and \"rejected\")\n",
    "def add_seq_len(example):\n",
    "    def get_tokenized_length(text):\n",
    "        tokenized = tokenizer(text)\n",
    "        return len(tokenized[\"input_ids\"])\n",
    "\n",
    "    chosen_len = get_tokenized_length(example[\"chosen\"])\n",
    "    reject_len = get_tokenized_length(example[\"rejected\"])\n",
    "    return {\n",
    "        \"chosen_len\": chosen_len,\n",
    "        \"rejected_len\": reject_len\n",
    "    }\n",
    "\n",
    "train_data = train_data.map(add_seq_len)\n",
    "\n",
    "# 2. remove rows which exceed the maximum sequence length\n",
    "train_data = train_data.filter(lambda example: example[\"chosen_len\"] <= max_seq_len and example[\"rejected_len\"] <= max_seq_len)\n",
    "train_data = train_data.remove_columns([\"chosen_len\", \"rejected_len\"])\n",
    "\n",
    "# show total number of filtered rows\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88199bf1-1931-4cb6-9f02-65385ae0a44a",
   "metadata": {},
   "source": [
    "Next we add the length of context's token (tokens without inferenced part by LLM) in the dataset, because we need the log probability for only inference part. (During training, we don't use the log probability in context part.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2dc2355-b86c-400b-bb9d-49656b5d83e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add token length of context (\"user\" part for question)\n",
    "def add_context_length(example):\n",
    "    chat_str = example[\"chosen\"]\n",
    "    target = \"<|im_start|>assistant\\n\"\n",
    "    start_idx = chat_str.rfind(target)\n",
    "    context_str = chat_str[:(start_idx + len(target))]\n",
    "\n",
    "    context_tensor = tokenizer(context_str)\n",
    "    context_length = len(context_tensor[\"input_ids\"])\n",
    "    return {\n",
    "        \"context_len\": context_length,\n",
    "    }\n",
    "\n",
    "train_data = train_data.map(add_context_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8692f4ef-32cf-450c-96ba-ddc36d1969a2",
   "metadata": {},
   "source": [
    "We build dataloader in order to feed data to the trainer.\n",
    "\n",
    "Each input's batch is tokenized as PyTorch tensors on GPU.<br>\n",
    "It's worth noting that here we use right-side padding for input's tokenization, unlike [RLHF tutorial](./01-rlhf-ppo.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60b2eefe-9821-40b3-9e0b-b9e661c60539",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "gradient_accumulation_steps = 8\n",
    "\n",
    "def collate_batch(batch):\n",
    "    # tokenize (convert to token ids and attention mask) and convert to tensor\n",
    "    chosen_list = [item[\"chosen\"] for item in batch]\n",
    "    reject_list = [item[\"rejected\"] for item in batch]\n",
    "    chosen_tensor = tokenizer(\n",
    "        chosen_list,\n",
    "        padding=True,\n",
    "        padding_side=\"right\",\n",
    "        return_tensors=\"pt\").to(device)\n",
    "    reject_tensor = tokenizer(\n",
    "        reject_list,\n",
    "        padding=True,\n",
    "        padding_side=\"right\",\n",
    "        return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # get token length of context\n",
    "    context_lens = [item[\"context_len\"] for item in batch]\n",
    "    context_lens = torch.tensor(context_lens).to(device)\n",
    "\n",
    "    return chosen_tensor, reject_tensor, context_lens\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4678a7-2dc4-4a68-a800-d89c8ff7827b",
   "metadata": {},
   "source": [
    "### 4. Train with DPO\n",
    "\n",
    "As you saw above, our objective is to minimize the loss formula (3). (I repeat this formula as follows.)\n",
    "\n",
    "$\\displaystyle L_{DPO} = -\\log \\sigma\\left( \\beta \\log \\frac{\\pi_{\\theta}(y_1|x)}{\\pi_{\\verb|ref|}(y_1|x)} - \\beta \\log \\frac{\\pi_{\\theta}(y_2|x)}{\\pi_{\\verb|ref|}(y_2|x)} \\right) \\;\\;\\;\\;\\;\\; (3)$\n",
    "\n",
    "In this equation, $y_1$ and $y_2$ are output's text (i.e., the sequence of tokens), and not a single token.<br>\n",
    "The log probability $\\log \\pi(y)$ is then induced by :\n",
    "\n",
    "$\\displaystyle \\log \\pi(y) = \\log \\left( \\pi(y^{(1)})\\pi(y^{(2)}) \\cdots \\pi(y^{(N)}) \\right) = \\log \\pi(y^{(1)}) + \\log \\pi(y^{(2)}) + \\cdots + \\log \\pi(y^{(N)}) = \\sum_{n=1}^N \\log \\pi(y^{(n)})$\n",
    "\n",
    "where $y^{(n)}$ is n-th token in output's text and $N$ is the length of tokens.\n",
    "\n",
    "> Note : In categorical disribution, the log probability $\\log P(a)$ can be derived by the negative value of cross-entropy error - i.e., ```-torch.nn.functional.cross_entropy(l, a)```, where ```l``` is logits and ```a``` is a taken action (i.e., a selected token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c81e2f38-6f5b-4f30-b959-6e387b44257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logprob(tokens, logits, inf_mask):\n",
    "    \"\"\"\n",
    "    Get log probability for the given token sequence.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tokens : torch.tensor((batch_size, seq_len), dtype=int)\n",
    "        Sequence of predicted tokens in batch.\n",
    "        (I note that it's not input's tokens, but predicted tokens.)\n",
    "    logits : torch.tensor((batch_size, seq_len, vocab_len), dtype=float)\n",
    "        Corresponding logits induced by the model.\n",
    "    inf_mask : torch.tensor((batch_size, seq_len), dtype=int)\n",
    "        Indicate which tokens are predicted.\n",
    "        (1 - Predicted token, 0 - Not predicted token)\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    log_probability : torch.tensor((batch_size), dtype=int)\n",
    "        Log probability of sequence.\n",
    "    \"\"\"\n",
    "\n",
    "    # get log probabilities for each token\n",
    "    logprb = -F.cross_entropy(logits.transpose(1,2), tokens, reduction=\"none\")\n",
    "    # filter into inference part\n",
    "    logprb[~inf_mask.bool()] = 0.0\n",
    "    # compute log probability of sequence (see above decription)\n",
    "    return logprb.sum(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f85f7f-19f4-4b50-9a96-6aa0f4d21eea",
   "metadata": {},
   "source": [
    "Now let's optimize a policy model with DPO.\n",
    "\n",
    "> Note : In order to prevent from GPU out of memory errors, I have used accumulation training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd986107-3098-4947-b467-ae7054e673d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (iter2705) 339/339 - loss 0.0880\n",
      "Epoch 2 (iter2705) 339/339 - loss 0.0186\n",
      "Epoch 3 (iter2705) 339/339 - loss 0.0136\n",
      "Epoch 4 (iter2705) 339/339 - loss 0.0129\n",
      "Epoch 5 (iter2705) 339/339 - loss 0.0126\n",
      "Epoch 6 (iter2705) 339/339 - loss 0.0126\n",
      "Epoch 7 (iter2705) 339/339 - loss 0.0126\n",
      "Epoch 8 (iter2705) 339/339 - loss 0.0127\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 8\n",
    "num_steps = math.ceil(len(dataloader) / gradient_accumulation_steps)\n",
    "\n",
    "beta = 0.1\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=pol_model.parameters(),\n",
    "    lr=2e-05,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-08,\n",
    ")\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=functools.partial(\n",
    "    _get_cosine_schedule,\n",
    "    num_training_steps=num_epochs*num_steps,\n",
    "    num_warmup_steps=math.ceil(num_epochs*num_steps*0.03),\n",
    "))\n",
    "\n",
    "# remove log file if exists\n",
    "log_file = \"loss_dpo.log\"\n",
    "if os.path.exists(log_file):\n",
    "    os.remove(log_file)\n",
    "\n",
    "# iterate epoch\n",
    "for epoch in range(num_epochs):\n",
    "    pol_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    record_loss = []\n",
    "\n",
    "    # iterate batch\n",
    "    for i, (chosen, reject, context_lens) in enumerate(dataloader):\n",
    "        itr_batch_size = len(context_lens)\n",
    "\n",
    "        # generate mask which narrows into only inference tokens\n",
    "        chosen_seq_len = chosen[\"input_ids\"].shape[1]\n",
    "        chosen_indices = torch.arange(chosen_seq_len, dtype=int).to(device)\n",
    "        chosen_infmask = chosen[\"attention_mask\"] * (chosen_indices >= context_lens.unsqueeze(-1)).int()\n",
    "\n",
    "        reject_seq_len = reject[\"input_ids\"].shape[1]\n",
    "        reject_indices = torch.arange(reject_seq_len, dtype=int).to(device)\n",
    "        reject_infmask = reject[\"attention_mask\"] * (reject_indices >= context_lens.unsqueeze(-1)).int()\n",
    "\n",
    "        # we don't use last token for inference\n",
    "        last_true_indices = (chosen_indices * chosen_infmask).argmax(-1)\n",
    "        chosen_infmask[torch.arange(itr_batch_size).to(device), last_true_indices] = 0\n",
    "\n",
    "        last_true_indices = (reject_indices * reject_infmask).argmax(-1)\n",
    "        reject_infmask[torch.arange(itr_batch_size).to(device), last_true_indices] = 0\n",
    "\n",
    "        # generated the predicted tokens\n",
    "        # (shift tokens to the left)\n",
    "        chosen_pred_ids = torch.roll(\n",
    "            chosen[\"input_ids\"],\n",
    "            shifts=-1,\n",
    "            dims=1,\n",
    "        )\n",
    "        reject_pred_ids = torch.roll(\n",
    "            reject[\"input_ids\"],\n",
    "            shifts=-1,\n",
    "            dims=1,\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # get logits with pi_ref (reference model)\n",
    "            chosen_logits_ref = ref_model(\n",
    "                input_ids=chosen[\"input_ids\"],\n",
    "                attention_mask=chosen[\"attention_mask\"],\n",
    "            ).logits\n",
    "            reject_logits_ref = ref_model(\n",
    "                input_ids=reject[\"input_ids\"],\n",
    "                attention_mask=reject[\"attention_mask\"],\n",
    "            ).logits\n",
    "\n",
    "            # get log probability of sequence\n",
    "            chosen_logprob_ref = get_logprob(chosen_pred_ids, chosen_logits_ref, chosen_infmask)\n",
    "            reject_logprob_ref = get_logprob(reject_pred_ids, reject_logits_ref, reject_infmask)\n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "            # get logits with pi_theta (policy model)\n",
    "            chosen_logits = pol_model(\n",
    "                input_ids=chosen[\"input_ids\"],\n",
    "                attention_mask=chosen[\"attention_mask\"],\n",
    "            ).logits\n",
    "            reject_logits = pol_model(\n",
    "                input_ids=reject[\"input_ids\"],\n",
    "                attention_mask=reject[\"attention_mask\"],\n",
    "            ).logits\n",
    "\n",
    "            # get log probability of sequence\n",
    "            chosen_logprob = get_logprob(chosen_pred_ids, chosen_logits, chosen_infmask)\n",
    "            reject_logprob = get_logprob(reject_pred_ids, reject_logits, reject_infmask)\n",
    "\n",
    "            # compute loss (see above equation (3)) :\n",
    "            # Note : to prevent from vanishing values, we first\n",
    "            # compute difference between 2 outputs in the same network\n",
    "            logdiff = (chosen_logprob - reject_logprob) - (chosen_logprob_ref - reject_logprob_ref)\n",
    "            loss = -F.logsigmoid(beta * logdiff).mean()\n",
    "            loss.backward()\n",
    "\n",
    "            # optimization by accumulation\n",
    "            if ((i + 1) % gradient_accumulation_steps == 0) or \\\n",
    "               (i + 1 == len(dataloader)):\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        # print log\n",
    "        record_loss.append(loss.item())\n",
    "        print(f\"Epoch {epoch+1} (iter{i+1}) {math.ceil((i + 1) / gradient_accumulation_steps)}/{num_steps} - loss {loss :5.4f}\", end=\"\\r\")\n",
    "\n",
    "    # save logging\n",
    "    epoch_average_loss = sum(record_loss)/len(record_loss)\n",
    "    print(f\"Epoch {epoch+1} (iter{i+1}) {math.ceil((i + 1) / gradient_accumulation_steps)}/{num_steps} - loss {epoch_average_loss :5.4f}\")\n",
    "    with open(log_file, \"a\") as f:\n",
    "        for l in record_loss:\n",
    "            f.write(\"%s\\n\" %l)\n",
    "\n",
    "# save checkpoint\n",
    "pol_model.save_pretrained(\"./llm_dpo\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf28f5e-459e-48e2-b35e-269e6a2f053f",
   "metadata": {},
   "source": [
    "Here I show loss transition during DPO training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "742be069-283c-498f-bdd4-c4f9d587ab9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_file = \"loss_dpo.log\"\n",
    "\n",
    "with open(log_file, \"r\") as f:\n",
    "    data = [float(line) for line in f]\n",
    "\n",
    "# show plot of every 50 interval average\n",
    "interval = 50\n",
    "avg = []\n",
    "for i in range(interval, len(data)):\n",
    "    tmp_list = data[i-interval+1:i+1]\n",
    "    avg.append(np.average(tmp_list))\n",
    "plt.plot(np.arange(interval, len(data)), avg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbff0d61-dfb1-4f00-a8ea-c7016f1f84d1",
   "metadata": {},
   "source": [
    "### 5. Test generated model\n",
    "\n",
    "Now let's generate outputs by using our trained model, and please compare to the outputs in the previous (SFT-ed model's) outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "082cd141-fb29-4104-a503-027faf770698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Question *****\n",
      "What do you most want to do right now?\n",
      "***** Answer *****\n",
      "I love starting my own business, too! Im registration Mia started it a couple years ago, and I've been inspired by her passion for selling handmade jewelry from scratch. She's been offering free online consultations and styling sessions, and I'm excited to start offering my own customized jewelry. It's a lot of work, but I love taking care of my family's special occasion, and I thrive under pressure.\n",
      "\n",
      "I've been working on building a client base by responding to all the about forms and pushing people to try out my products. It's been a challenge, but I'm feeling like I'm making something truly unique and memorable this time around. We recently did a pop-up store in downtown NYC, and it was amazing to see the crowd and the judgments that come from less formality.\n",
      "\n",
      "I've been swamped with work lately, but I just want to prioritize this endeavour and build things!! Every step of the way, I'm just trying to be my best and embrace my inner artist. What are your thoughts on this project? Do you think I've ticked all the boxes yet?! ðŸ˜Š (wink wink)\n",
      "\n",
      "***** Question *****\n",
      "What is the best gift to give a friend who loves the outdoors?\n",
      "***** Answer *****\n",
      "I'm so glad you asked! Knowing that your friend loves the outdoors, I envision a game that's just as much fun as it is inspirational. Maybe a scavenger hunt or a cross-country train scavenger hunt? We can do everything from dog walking to kayaking or even trying our hand at bird watching!\n",
      "\n",
      "This gift can be a great way to get them excited about this hobby and show them you care. Why not find someone to come over for a scavenger hunt? You can bring along some fun items like rope, blankets, or even a kid-friendly photo album to share on each trail at the end of it.\n",
      "\n",
      "Of course, no huge outdoors gift would be complete without a personalized photo album. I'll share with you how I discovered a beautiful bird and pick your favorite photo of it, too (or you can even arrange for my friend to take a photo of the animal while we're hiking!). It's not just about the photo â€“ it's about capturing memories that will treasure you for years to come.\n",
      "\n",
      "This gift will be a conversation starter, someone to show you around, and something to look forward to after a long day at the beach or hiking. Keep a close eye out for your new adventureer, and that's always going to be a thrill for you!\n",
      "\n",
      "***** Question *****\n",
      "How do you relax after something bad happens?\n",
      "***** Answer *****\n",
      "Relaxing after a tough time? I mean, just the little things in life can make the whole day feel brighter. I remember when my best friend was having a quick bar fight on the lake, and of course, your usual spots seemed to go on forever. Now, I know it can feel exhausting at times, but I remember how silly that was... listening to her walk away from a fight or trying to stand up to her rage on my own stairs! (laughs)\n",
      "\n",
      "Sometimes, when I'm racing against the clock and trying to absorb all that was happening, I'll try to do things slow. Like, try to step outside for a little while and take in the silence of the forest... that sounds amazing right now, but it really just gives me a nice break from the bullhorn!\n",
      "\n",
      "I also like to listen to some relaxing music, like my old acoustic guitar or maybe even my digital guitar. I swear, even though I chat with my guitar, it's still cool to understand some of the lyrics! (laughs)\n",
      "\n",
      "And, if you're lucky, you might have a big tale to tell. It's always a silly story, full of laughs and tears, right? And it helps me move on from the heartache, even if it's just a little bit of bitching around the gym. (gulps hard) But, seriously, it's just the usual sightseeing in a park or lounging at the beach... what do you need? ðŸ˜„\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# build a batch of questions\n",
    "# (To use cache, we apply left-side padding.)\n",
    "#\n",
    "\n",
    "messages = [\n",
    "    \"What do you most want to do right now?\",\n",
    "    \"What is the best gift to give a friend who loves the outdoors?\",\n",
    "    \"How do you relax after something bad happens?\",\n",
    "]\n",
    "inputs = [f\"<|im_start|>user\\n{m}<|im_end|>\\n<|im_start|>assistant\\n\" for m in messages]\n",
    "input_batch = tokenizer(\n",
    "    inputs,\n",
    "    padding=True,\n",
    "    padding_side=\"left\",\n",
    "    return_tensors=\"pt\").to(device)\n",
    "input_seq_len = input_batch[\"input_ids\"].shape[1]\n",
    "\n",
    "#\n",
    "# generate model's outputs\n",
    "#\n",
    "\n",
    "pol_model.eval()\n",
    "with torch.no_grad():\n",
    "    iids, mask = generate_token_by_policy(\n",
    "        input_batch,\n",
    "        pol_model,\n",
    "        tokenizer,\n",
    "        max_seq_len,\n",
    "    )\n",
    "iids = iids[:,input_seq_len:]\n",
    "outputs = tokenizer.batch_decode(iids, skip_special_tokens=True)\n",
    "\n",
    "#\n",
    "# print results\n",
    "#\n",
    "\n",
    "for i in range(len(messages)):\n",
    "    print(\"***** Question *****\")\n",
    "    print(messages[i])\n",
    "    print(\"***** Answer *****\")\n",
    "    print(outputs[i])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0544681-f49d-4d8c-abf5-f8531e97d6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
